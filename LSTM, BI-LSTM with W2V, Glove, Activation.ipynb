{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "lstm-sentiment-analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmithaUW/FNC-1-Stance-Detection/blob/master/LSTM%2C%20BI-LSTM%20with%20W2V%2C%20Glove%2C%20Activation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3nCL7GBPlU",
        "colab_type": "code",
        "outputId": "50d8c7a5-5f8a-4854-9a61-fa6159abac11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "!unzip fnc-1.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  fnc-1.zip\n",
            "   creating: fnc-1/\n",
            "  inflating: fnc-1/competition_test_bodies.csv  \n",
            "  inflating: fnc-1/competition_test_stances.csv  \n",
            "  inflating: fnc-1/competition_test_stances_unlabeled.csv  \n",
            "  inflating: fnc-1/README.md         \n",
            "  inflating: fnc-1/scorer.py         \n",
            "  inflating: fnc-1/test_bodies.csv   \n",
            "  inflating: fnc-1/test_stances_unlabeled.csv  \n",
            "  inflating: fnc-1/train_bodies.csv  \n",
            "  inflating: fnc-1/train_stances.csv  \n",
            "  inflating: fnc-1/train_stances.random.csv  \n",
            "--2019-07-23 14:22:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-07-23 14:22:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-07-23 14:22:49--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  64.2MB/s    in 32s     \n",
            "\n",
            "2019-07-23 14:23:21 (26.0 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AIXbyGnH5pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_config = tf.ConfigProto()\n",
        "tf_config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=tf_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFrPwYXPBPlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(1003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pFRP93ZBPlg",
        "colab_type": "text"
      },
      "source": [
        "### Python 3.6.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XChgIilrBPlt",
        "colab_type": "text"
      },
      "source": [
        "### Specify Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkcVr6KmBPlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folder locations\n",
        "W2V_DIR = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
        "DATA_DIR = 'fnc-1/'\n",
        "Glove = 'glove.6B.200d.txt'\n",
        "\n",
        "# These are some hyperparameters that can be tuned\n",
        "MAX_SENT_LEN = 170\n",
        "MAX_VOCAB_SIZE = 400000\n",
        "LSTM_DIM = 128\n",
        "EMBEDDING_DIM = 200\n",
        "#EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 200\n",
        "N_EPOCHS = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cauQcGQ0BPlx",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9mFRE-nBPlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the text files of positive and negative sentences\n",
        "train_bodies = pd.read_csv(DATA_DIR+'train_bodies.csv')\n",
        "train_stances = pd.read_csv(DATA_DIR+'train_stances.csv')\n",
        "\n",
        "test_bodies = pd.read_csv(DATA_DIR+'test_bodies.csv')\n",
        "test_stances_unlabeled = pd.read_csv(DATA_DIR+'test_stances_unlabeled.csv')\n",
        "\n",
        "competetion_bodies = pd.read_csv(DATA_DIR+'competition_test_bodies.csv')\n",
        "competetion_stances = pd.read_csv(DATA_DIR+'competition_test_stances.csv')\n",
        "\n",
        "competetion_unlabeled = pd.read_csv(DATA_DIR+'competition_test_stances_unlabeled.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNG5eReVBPl2",
        "colab_type": "code",
        "outputId": "ebb2850e-f094-4ff7-a2d1-508aa214385d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of Body sentences:', len(train_bodies['articleBody']))\n",
        "print('Number of Headlines sentences:', len(train_stances['Headline']))\n",
        "\n",
        "train = train_stances.join(train_bodies.set_index('Body ID'), on='Body ID')\n",
        "test = test_stances_unlabeled.join(test_bodies.set_index('Body ID'), on='Body ID')\n",
        "comp = competetion_stances.join(competetion_bodies.set_index('Body ID'), on='Body ID')\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Body sentences: 1683\n",
            "Number of Headlines sentences: 49972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD66lBEfBPl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.replace('unrelated',1,True)\n",
        "train.replace('agree',2,True)\n",
        "train.replace('disagree',3,True)\n",
        "train.replace('discuss',4,True)\n",
        "\n",
        "comp.replace('unrelated',1,True)\n",
        "comp.replace('agree',2,True)\n",
        "comp.replace('disagree',3,True)\n",
        "comp.replace('discuss',4,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guPDNT28BPmJ",
        "colab_type": "code",
        "outputId": "ad3a1a64-8399-4cc2-fb54-ff8527f909cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Pre-processing involves removal of puctuations and converting text to lower case\n",
        "word_seq_headline_train = [text_to_word_sequence(sent) for sent in train['Headline']]\n",
        "word_seq_bodies_train = [text_to_word_sequence(sent) for sent in train['articleBody']]\n",
        "\n",
        "word_seq_headline_test = [text_to_word_sequence(sent) for sent in test['Headline']]\n",
        "word_seq_bodies_test = [text_to_word_sequence(sent) for sent in test['articleBody']]\n",
        "\n",
        "word_seq_headline_comp = [text_to_word_sequence(sent) for sent in comp['Headline']]\n",
        "word_seq_bodies_comp = [text_to_word_sequence(sent) for sent in comp['articleBody']]\n",
        "\n",
        "print('90th Percentile Sentence Length:', np.percentile([len(seq) for seq in word_seq_headline_train], 90))\n",
        "print('90th Percentile Sentence Length:', np.percentile([len(seq) for seq in word_seq_bodies_train], 90))\n",
        "\n",
        "print('90th Percentile Sentence Length:', np.percentile([len(seq) for seq in word_seq_headline_test], 90))\n",
        "print('90th Percentile Sentence Length:', np.percentile([len(seq) for seq in word_seq_bodies_test], 90))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90th Percentile Sentence Length: 16.0\n",
            "90th Percentile Sentence Length: 683.0\n",
            "90th Percentile Sentence Length: 16.0\n",
            "90th Percentile Sentence Length: 657.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2PHD9sXa_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "for i in range(len(word_seq_headline_train)):\n",
        "  word_seq.append(word_seq_headline_train[i])\n",
        "  \n",
        "for i in range(len(word_seq_bodies_train)):\n",
        "  word_seq.append(word_seq_bodies_train[i])\n",
        "\n",
        "for i in range(len(word_seq_headline_test)):\n",
        "  word_seq.append(word_seq_headline_test[i])\n",
        "\n",
        "for i in range(len(word_seq_bodies_test)):\n",
        "  word_seq.append(word_seq_bodies_test[i])\n",
        "  \n",
        "for i in range(len(word_seq_headline_comp)):\n",
        "  word_seq.append(word_seq_headline_comp[i])\n",
        "  \n",
        "for i in range(len(word_seq_bodies_comp)):\n",
        "  word_seq.append(word_seq_bodies_comp[i])\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jsgYwiweMP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_train)):\n",
        "  word_seq_headline_train[i].extend(word_seq_bodies_train[i])\n",
        "\n",
        "  \n",
        "for i in range (len(word_seq_headline_test)):\n",
        "  word_seq_headline_test[i].extend(word_seq_bodies_test[i])\n",
        "  \n",
        "\n",
        "for i in range (len(word_seq_headline_comp)):\n",
        "  word_seq_headline_comp[i].extend(word_seq_bodies_comp[i])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCNFhX55BPmP",
        "colab_type": "code",
        "outputId": "6277b8b8-de4b-468a-f477-11c8d2aac8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq])\n",
        "\n",
        "print(\"Number of words in vocabulary:\", len(tokenizer.word_index))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 22380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRO2s1RsBPmX",
        "colab_type": "code",
        "outputId": "7cbff7af-7c4b-4fed-b50a-8757ecd246f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Convert the sequence of words to sequnce of indices\n",
        "X_train = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_train])\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_train = train['Stance']\n",
        "y_train = y_train.values\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "\n",
        "X_comp = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])\n",
        "X_comp = pad_sequences(X_comp, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_comp = comp['Stance']\n",
        "y_comp = y_comp.values\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49972, 170)\n",
            "(49972,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmTwVponVIE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y_train)\n",
        "encoded_train = encoder_train.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_train)\n",
        "\n",
        "encoder_comp = LabelEncoder()\n",
        "encoder_comp.fit(y_comp)\n",
        "encoded_comp = encoder_comp.transform(y_comp)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_comp = np_utils.to_categorical(encoded_comp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONYq7augBPmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, dummy_y_train, random_state=10, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UraYlyN0_B",
        "colab_type": "code",
        "outputId": "f018455d-0820-4b6e-838b-3aeb8dc000a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(W2V_DIR, binary=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIhw7CGQBPm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9cc31eee-0984-47eb-a761-a75f67a6d514"
      },
      "source": [
        "glove2word2vec(glove_input_file=Glove, word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeRlWLI9BPm6",
        "colab_type": "code",
        "outputId": "d51f3090-a92b-440e-c75c-851a6643d85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of words in this pre-trained w2v model:', len(embeddings.vocab))\n",
        "print('Dimension of w2v:', embeddings.vector_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in this pre-trained w2v model: 400000\n",
            "Dimension of w2v: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD-xjcq2BPnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an embedding matrix containing only the word's in our vocabulary\n",
        "# If the word does not have a pre-trained embedding, then randomly initialize the embedding\n",
        "\n",
        "embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
        "\n",
        "for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix[i] = embeddings_vector\n",
        "        \n",
        "del embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peHyVp5ABPnR",
        "colab_type": "text"
      },
      "source": [
        "### Keras Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1-RnU3nBPnR",
        "colab_type": "code",
        "outputId": "c7045456-da9a-4569-fd15-795c8260dc85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer' \n",
        "                          ))\n",
        "#model.add(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer'))\n",
        "model.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
        "model.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "model.add(Dense(4, activation='softmax', name='output_layer'))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 15:20:13.645868 139925416753024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0723 15:20:13.651262 139925416753024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0723 15:20:13.676970 139925416753024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0723 15:20:13.691087 139925416753024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0723 15:20:13.692237 139925416753024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0723 15:20:14.417567 139925416753024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0723 15:20:14.418791 139925416753024 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXveDgyABPnV",
        "colab_type": "code",
        "outputId": "194dad32-de9c-4807-83d2-00e284fee353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_embedding_layer (Embedd (None, None, 200)         4476200   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 4,814,124\n",
            "Trainable params: 4,814,124\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUDZhtpNBPnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkHOvOqHBPnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwKFLaLVbBWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Bi-LSTM+Glove', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSZxQTuJhcxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('BiLSTM+Glove.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6IgJCLooBPnw",
        "colab_type": "text"
      },
      "source": [
        "**Bi-directional W2V+Glove with activation layer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIf6S2dEBPnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=False, name='word_embedding_layer', \n",
        "                          mask_zero=True)) # trainable=True results in overfitting\n",
        "\n",
        "#model.add(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer')) # Can try Bidirectional-LSTM\n",
        "model.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
        "\n",
        "model.add(Dense(32, name='dense_1'))\n",
        "# model.add(BatchNormalization(name='bn_1')) # BN did not really help with performance \n",
        "model.add(Dropout(rate=0.3, name='dropout_1')) # Can try varying dropout rates\n",
        "model.add(Activation(activation='relu', name='activation_1'))\n",
        "\n",
        "model.add(Dense(8, name='dense_2'))\n",
        "# model.add(BatchNormalization(name='bn_2'))\n",
        "model.add(Dropout(rate=0.3, name='dropout_2'))\n",
        "model.add(Activation(activation='relu', name='activation_2'))\n",
        "\n",
        "model.add(Dense(4, activation='softmax', name='output_layer'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BZWnWkbBPn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW14Vp6IBPn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCTRMmeBPn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Bi-LSTM+Glove+Activation', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFxT2Tg0BPoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('BiLSTMActivation.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}