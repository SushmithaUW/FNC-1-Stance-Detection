{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmithaUW/FNC-1-Stance-Detection/blob/master/Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-2QRvO3nTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip fnc-1.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97j0-dEN3wsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_config = tf.ConfigProto()\n",
        "tf_config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=tf_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1068o5Ec30RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(1003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBZkt-0M32c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folder locations\n",
        "W2V_DIR = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
        "DATA_DIR = 'fnc-1/'\n",
        "Glove = 'glove.6B.200d.txt'\n",
        "\n",
        "# These are some hyperparameters that can be tuned\n",
        "MAX_SENT_LEN = 170\n",
        "MAX_VOCAB_SIZE = 400000\n",
        "LSTM_DIM = 128\n",
        "EMBEDDING_DIM = 200\n",
        "BATCH_SIZE = 200\n",
        "N_EPOCHS = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-nb5Ea356p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bodies = pd.read_csv(DATA_DIR+'train_bodies.csv')\n",
        "train_stances = pd.read_csv(DATA_DIR+'train_stances.csv')\n",
        "\n",
        "test_bodies = pd.read_csv(DATA_DIR+'test_bodies.csv')\n",
        "test_stances_unlabeled = pd.read_csv(DATA_DIR+'test_stances_unlabeled.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RTK-ok1376-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train_stances.join(train_bodies.set_index('Body ID'), on='Body ID')\n",
        "test = test_stances_unlabeled.join(test_bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkANQVXb39g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.replace('unrelated',1,True)\n",
        "train.replace('agree',2,True)\n",
        "train.replace('disagree',3,True)\n",
        "train.replace('discuss',4,True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WjtKGtj3_K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq_headline_train = [text_to_word_sequence(sent) for sent in train['Headline']]\n",
        "word_seq_bodies_train = [text_to_word_sequence(sent) for sent in train['articleBody']]\n",
        "\n",
        "word_seq_headline_test = [text_to_word_sequence(sent) for sent in test['Headline']]\n",
        "word_seq_bodies_test = [text_to_word_sequence(sent) for sent in test['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ46jPKW4A7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "for i in range(len(word_seq_headline_train)):\n",
        "  word_seq.append(word_seq_headline_train[i])\n",
        "  \n",
        "for i in range(len(word_seq_bodies_train)):\n",
        "  word_seq.append(word_seq_bodies_train[i])\n",
        "\n",
        "for i in range(len(word_seq_headline_test)):\n",
        "  word_seq.append(word_seq_headline_test[i])\n",
        "\n",
        "for i in range(len(word_seq_bodies_test)):\n",
        "  word_seq.append(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHRgKBRc4DeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_train)):\n",
        "  word_seq_headline_train[i].extend(word_seq_bodies_train[i])\n",
        "\n",
        "  \n",
        "for i in range (len(word_seq_headline_test)):\n",
        "  word_seq_headline_test[i].extend(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6-scEWk4GzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJoschJq4H4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the sequence of words to sequnce of indices\n",
        "X_train = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_train])\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_train = train['Stance']\n",
        "y_train = y_train.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmURGJgl4Ll9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y_train)\n",
        "encoded_train = encoder_train.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS8TpYpQ4MHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, dummy_y_train, random_state=10, test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET2-Sil_4N4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove2word2vec(glove_input_file=Glove, word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)\n",
        "\n",
        "embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
        "\n",
        "for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix[i] = embeddings_vector\n",
        "        \n",
        "del embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZS4m1Ae4Wep",
        "colab_type": "code",
        "outputId": "5c4e7989-762e-439d-fc37-23fd3b201952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model_Uni = Sequential()\n",
        "model_Uni.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer' \n",
        "                          ))\n",
        "model_Uni.add(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer'))\n",
        "model_Uni.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "model_Uni.add(Dense(4, activation='softmax', name='output_layer'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 23:43:42.792661 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 23:43:42.797942 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 23:43:42.803703 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 23:43:42.822780 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0725 23:43:42.823753 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0725 23:43:43.186381 140082118629248 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0725 23:43:43.187825 140082118629248 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ak4PzH24X5A",
        "colab_type": "code",
        "outputId": "b2899a16-6e68-4af7-aeb6-6f7f692692ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model_Bi = Sequential()\n",
        "model_Bi.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer' \n",
        "                          ))\n",
        "model_Bi.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
        "model_Bi.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "model_Bi.add(Dense(4, activation='softmax', name='output_layer'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 23:43:43.814962 140082118629248 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9cgpd604boB",
        "colab_type": "code",
        "outputId": "6df6d964-4563-4c9e-c376-7649ed7cccca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "print (model_Uni.summary())\n",
        "print (model_Bi.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_embedding_layer (Embedd (None, None, 200)         4476200   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 128)               168448    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 4,645,164\n",
            "Trainable params: 4,645,164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_embedding_layer (Embedd (None, None, 200)         4476200   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 4,814,124\n",
            "Trainable params: 4,814,124\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqUeGdcg4drJ",
        "colab_type": "code",
        "outputId": "1c927559-0938-4595-bad5-8476d2369c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model_Uni.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_Bi.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 23:43:43.879540 140082118629248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgLuj9bx4ePC",
        "colab_type": "code",
        "outputId": "79128f33-c47f-4352-8142-ffd93c39fe73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "model_Uni.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "model_Bi.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 23:43:44.091705 140082118629248 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44974 samples, validate on 4998 samples\n",
            "Epoch 1/1\n",
            "44974/44974 [==============================] - 333s 7ms/step - loss: 0.8203 - acc: 0.7228 - val_loss: 0.6973 - val_acc: 0.7429\n",
            "Train on 44974 samples, validate on 4998 samples\n",
            "Epoch 1/1\n",
            "44974/44974 [==============================] - 716s 16ms/step - loss: 0.7636 - acc: 0.7336 - val_loss: 0.6335 - val_acc: 0.7463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66a97f2780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwzzACAU4gj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_Uni.save('LSTM+glove.h5')\n",
        "model_Bi.save('BiLSTM+glove.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9VF7odjgRBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "competetion_bodies = pd.read_csv(DATA_DIR+'competition_test_bodies.csv')\n",
        "competetion_stances = pd.read_csv(DATA_DIR+'competition_test_stances.csv')\n",
        "\n",
        "competetion_unlabeled = pd.read_csv(DATA_DIR+'competition_test_stances_unlabeled.csv')\n",
        "\n",
        "comp = competetion_stances.join(competetion_bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-suGF7TrgS4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp.replace('unrelated',1,True)\n",
        "comp.replace('agree',2,True)\n",
        "comp.replace('disagree',3,True)\n",
        "comp.replace('discuss',4,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB8SyiBngToI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq_headline_comp = [text_to_word_sequence(sent) for sent in comp['Headline']]\n",
        "word_seq_bodies_comp = [text_to_word_sequence(sent) for sent in comp['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlj8hWkjgVxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_comp)):\n",
        "  word_seq_headline_comp[i].extend(word_seq_bodies_comp[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzgkFrU1gXvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SIjdpblgZeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_comp = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])\n",
        "X_comp = pad_sequences(X_comp, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_comp = comp['Stance']\n",
        "y_comp = y_comp.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAcQ-bl4gcGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_comp = LabelEncoder()\n",
        "encoder_comp.fit(y_comp)\n",
        "encoded_comp = encoder_comp.transform(y_comp)\n",
        "dummy_y_comp = np_utils.to_categorical(encoded_comp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-i4Cb0gd3s",
        "colab_type": "code",
        "outputId": "11aa39d0-1a47-4c71-9742-2c19ee7f5076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_Uni = model_Uni.predict(X_comp)\n",
        "score,acc = model_Uni.evaluate(X_comp, dummy_y_comp)\n",
        "print (\"LSTM with glove \",score)\n",
        "\n",
        "y_Bi = model_Bi.predict(X_comp)\n",
        "score,acc = model_Bi.evaluate(X_comp, dummy_y_comp)\n",
        "print (\"BiLSTM with glove \",score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25413/25413 [==============================] - 47s 2ms/step\n",
            "LSTM with W2V  0.8553008107974295\n",
            "25413/25413 [==============================] - 93s 4ms/step\n",
            "BiLSTM with W2V  0.9140186185224726\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}