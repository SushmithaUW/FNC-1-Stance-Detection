{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictions on Competetion Data set.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmithaUW/FNC-1-Stance-Detection/blob/master/Predictions_on_Competetion_Unlabelled_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiXEU_I5OsN6",
        "colab_type": "text"
      },
      "source": [
        "**Bidirectional LSTM with W2V and GloVe**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_4yI44CpPJ4s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DBhA4MSOxR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip fnc-1.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uFotTtOvuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_config = tf.ConfigProto()\n",
        "tf_config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=tf_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKGy7kMmP7zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folder locations\n",
        "W2V_DIR = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
        "DATA_DIR = 'fnc-1/'\n",
        "Glove = 'glove.6B.200d.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZoQPCbHPvf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(1003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "583VJl55REDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SENT_LEN = 170\n",
        "MAX_VOCAB_SIZE = 400000\n",
        "LSTM_DIM = 128\n",
        "EMBEDDING_DIM = 200\n",
        "#EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 200\n",
        "N_EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd1SD1a3P2nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "competetion_bodies = pd.read_csv(DATA_DIR+'competition_test_bodies.csv')\n",
        "competetion_stances = pd.read_csv(DATA_DIR+'competition_test_stances.csv')\n",
        "\n",
        "competetion_unlabeled = pd.read_csv(DATA_DIR+'competition_test_stances_unlabeled.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwP1Ud2xQARs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp = competetion_stances.join(competetion_bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOymCGjZQH2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp.replace('unrelated',1,True)\n",
        "comp.replace('agree',2,True)\n",
        "comp.replace('disagree',3,True)\n",
        "comp.replace('discuss',4,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-9iGLG5QMn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq_headline_comp = [text_to_word_sequence(sent) for sent in comp['Headline']]\n",
        "word_seq_bodies_comp = [text_to_word_sequence(sent) for sent in comp['articleBody']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TANwyfWzQtax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "for i in range(len(word_seq_bodies_comp)):\n",
        "  word_seq.append(word_seq_bodies_comp[i])\n",
        "  \n",
        "for i in range(len(word_seq_bodies_comp)):\n",
        "  word_seq.append(word_seq_bodies_comp[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZMKiUYxQTUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_comp)):\n",
        "  word_seq_headline_comp[i].extend(word_seq_bodies_comp[i])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl8ouRtQQV_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s5LVTuKRJlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_comp = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])\n",
        "X_comp = pad_sequences(X_comp, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_comp = comp['Stance']\n",
        "y_comp = y_comp.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjYEY9NOTPkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_comp = LabelEncoder()\n",
        "encoder_comp.fit(y_comp)\n",
        "encoded_comp = encoder_comp.transform(y_comp)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_comp = np_utils.to_categorical(encoded_comp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbhfM7SDR24d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "e528fd88-0cad-477b-8d47-c68ab40b0a49"
      },
      "source": [
        "from keras import models\n",
        "model = models.load_model('BiLSTM.h5')\n",
        "y_pred = model.predict(X_comp)\n",
        "score,acc = model.evaluate(X_comp, dummy_y_comp)\n",
        "print (score)\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 18:26:37.060389 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0723 18:26:37.069651 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0723 18:26:37.085984 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0723 18:26:38.161896 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0723 18:26:38.170127 140507819177856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0723 18:26:38.171281 140507819177856 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0723 18:26:38.326400 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0723 18:26:38.473260 140507819177856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0723 18:26:38.596786 140507819177856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25413/25413 [==============================] - 82s 3ms/step\n",
            "0.8605693960698311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RBrDYzQgp3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = [np.argmax(p, axis = -1) for p in y_pred]\n",
        "for i in range(len(outputs)):\n",
        "    if outputs[i] == 0: outputs[i] = \"unrelated\"\n",
        "    if outputs[i] == 1: outputs[i] = \"disagree\"\n",
        "    if outputs[i] == 2: outputs[i] = \"agree\"\n",
        "    if outputs[i] == 3: outputs[i] = \"discuss\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SqYXG5mgsfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predicted = {}\n",
        "Predicted = pd.DataFrame({'Stance': outputs})\n",
        "result = pd.concat([competetion_unlabeled, Predicted], axis=1, sort=False)\n",
        "result.to_csv('./fnc-1/competetion_labelled.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}