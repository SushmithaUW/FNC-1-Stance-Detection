{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of W2V.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmithaUW/FNC-1-Stance-Detection/blob/master/Copy_of_Copy_of_W2V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtO9NtyfwMmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip fnc-1.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1xQ0sj8wR0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_config = tf.ConfigProto()\n",
        "tf_config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=tf_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHlsw6uSwXPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(1003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPMP7l2swZOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folder locations\n",
        "W2V_DIR = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
        "DATA_DIR = 'fnc-1/'\n",
        "Glove = 'glove.6B.200d.txt'\n",
        "\n",
        "# These are some hyperparameters that can be tuned\n",
        "MAX_SENT_LEN = 170\n",
        "MAX_VOCAB_SIZE = 400000\n",
        "LSTM_DIM = 128\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 200\n",
        "N_EPOCHS = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEnN8aWQwf0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bodies = pd.read_csv(DATA_DIR+'train_bodies.csv')\n",
        "train_stances = pd.read_csv(DATA_DIR+'train_stances.csv')\n",
        "\n",
        "test_bodies = pd.read_csv(DATA_DIR+'test_bodies.csv')\n",
        "test_stances_unlabeled = pd.read_csv(DATA_DIR+'test_stances_unlabeled.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0C4PRpawiMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train_stances.join(train_bodies.set_index('Body ID'), on='Body ID')\n",
        "test = test_stances_unlabeled.join(test_bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWD8mRbgwixG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.replace('unrelated',1,True)\n",
        "train.replace('agree',2,True)\n",
        "train.replace('disagree',3,True)\n",
        "train.replace('discuss',4,True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msRxXYcCwm03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq_headline_train = [text_to_word_sequence(sent) for sent in train['Headline']]\n",
        "word_seq_bodies_train = [text_to_word_sequence(sent) for sent in train['articleBody']]\n",
        "\n",
        "word_seq_headline_test = [text_to_word_sequence(sent) for sent in test['Headline']]\n",
        "word_seq_bodies_test = [text_to_word_sequence(sent) for sent in test['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gezR48R6woQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "for i in range(len(word_seq_headline_train)):\n",
        "  word_seq.append(word_seq_headline_train[i])\n",
        "  \n",
        "for i in range(len(word_seq_bodies_train)):\n",
        "  word_seq.append(word_seq_bodies_train[i])\n",
        "\n",
        "for i in range(len(word_seq_headline_test)):\n",
        "  word_seq.append(word_seq_headline_test[i])\n",
        "\n",
        "for i in range(len(word_seq_bodies_test)):\n",
        "  word_seq.append(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIyGgfAlwr3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_train)):\n",
        "  word_seq_headline_train[i].extend(word_seq_bodies_train[i])\n",
        "\n",
        "  \n",
        "for i in range (len(word_seq_headline_test)):\n",
        "  word_seq_headline_test[i].extend(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcXpK1mewuZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMKKY8D2w1q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the sequence of words to sequnce of indices\n",
        "X_train = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_train])\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_train = train['Stance']\n",
        "y_train = y_train.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6O-uzNnw4MO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y_train)\n",
        "encoded_train = encoder_train.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bqUf1Phw7wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, dummy_y_train, random_state=10, test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BxPNiRrw-NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(W2V_DIR, binary=True)\n",
        "embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
        "\n",
        "for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix[i] = embeddings_vector\n",
        "        \n",
        "del embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5OmQWcHxGez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model_Uni = Sequential()\n",
        "model_Uni.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer' \n",
        "                          ))\n",
        "model_Uni.add(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer'))\n",
        "model_Uni.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "model_Uni.add(Dense(4, activation='softmax', name='output_layer'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5aStB43xTSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model_Bi = Sequential()\n",
        "model_Bi.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer' \n",
        "                          ))\n",
        "model_Bi.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
        "model_Bi.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "model_Bi.add(Dense(4, activation='softmax', name='output_layer'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ionw2NcixZXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (model_Uni.summary())\n",
        "print (model_Bi.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9ePxmxlxiIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_Uni.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_Bi.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p07DU1BfxoqQ",
        "colab_type": "code",
        "outputId": "d79baec7-5ccc-49b7-8ba9-b8c3d8ee93d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "model_Uni.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "model_Bi.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 17:09:52.798464 140613694261120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44974 samples, validate on 4998 samples\n",
            "Epoch 1/10\n",
            "44974/44974 [==============================] - 355s 8ms/step - loss: 0.7660 - acc: 0.7425 - val_loss: 0.6246 - val_acc: 0.7769\n",
            "Epoch 2/10\n",
            "44974/44974 [==============================] - 353s 8ms/step - loss: 0.6059 - acc: 0.7878 - val_loss: 0.5798 - val_acc: 0.7867\n",
            "Epoch 3/10\n",
            "44974/44974 [==============================] - 347s 8ms/step - loss: 0.5577 - acc: 0.8001 - val_loss: 0.5587 - val_acc: 0.7935\n",
            "Epoch 4/10\n",
            "44974/44974 [==============================] - 328s 7ms/step - loss: 0.5338 - acc: 0.8038 - val_loss: 0.5556 - val_acc: 0.7927\n",
            "Epoch 5/10\n",
            "44974/44974 [==============================] - 325s 7ms/step - loss: 0.5071 - acc: 0.8102 - val_loss: 0.5541 - val_acc: 0.7963\n",
            "Epoch 6/10\n",
            "44974/44974 [==============================] - 331s 7ms/step - loss: 0.4888 - acc: 0.8159 - val_loss: 0.5467 - val_acc: 0.7989\n",
            "Epoch 7/10\n",
            "44974/44974 [==============================] - 327s 7ms/step - loss: 0.4734 - acc: 0.8214 - val_loss: 0.5467 - val_acc: 0.8017\n",
            "Epoch 8/10\n",
            "44974/44974 [==============================] - 331s 7ms/step - loss: 0.4585 - acc: 0.8232 - val_loss: 0.5587 - val_acc: 0.8009\n",
            "Epoch 9/10\n",
            "44974/44974 [==============================] - 331s 7ms/step - loss: 0.4485 - acc: 0.8269 - val_loss: 0.5701 - val_acc: 0.7999\n",
            "Epoch 10/10\n",
            "44974/44974 [==============================] - 342s 8ms/step - loss: 0.4411 - acc: 0.8293 - val_loss: 0.5611 - val_acc: 0.7999\n",
            "Train on 44974 samples, validate on 4998 samples\n",
            "Epoch 1/10\n",
            "44974/44974 [==============================] - 800s 18ms/step - loss: 0.7258 - acc: 0.7461 - val_loss: 0.5532 - val_acc: 0.7971\n",
            "Epoch 2/10\n",
            "44974/44974 [==============================] - 844s 19ms/step - loss: 0.5100 - acc: 0.8115 - val_loss: 0.4583 - val_acc: 0.8281\n",
            "Epoch 3/10\n",
            "44974/44974 [==============================] - 822s 18ms/step - loss: 0.3999 - acc: 0.8514 - val_loss: 0.3850 - val_acc: 0.8549\n",
            "Epoch 4/10\n",
            "44974/44974 [==============================] - 792s 18ms/step - loss: 0.3171 - acc: 0.8819 - val_loss: 0.3354 - val_acc: 0.8719\n",
            "Epoch 5/10\n",
            "44974/44974 [==============================] - 817s 18ms/step - loss: 0.2503 - acc: 0.9052 - val_loss: 0.2974 - val_acc: 0.8862\n",
            "Epoch 6/10\n",
            "44974/44974 [==============================] - 718s 16ms/step - loss: 0.2026 - acc: 0.9234 - val_loss: 0.2677 - val_acc: 0.8978\n",
            "Epoch 7/10\n",
            "44974/44974 [==============================] - 868s 19ms/step - loss: 0.1675 - acc: 0.9387 - val_loss: 0.2472 - val_acc: 0.9118\n",
            "Epoch 8/10\n",
            "44974/44974 [==============================] - 845s 19ms/step - loss: 0.1399 - acc: 0.9475 - val_loss: 0.2301 - val_acc: 0.9200\n",
            "Epoch 9/10\n",
            "44974/44974 [==============================] - 711s 16ms/step - loss: 0.1173 - acc: 0.9577 - val_loss: 0.2354 - val_acc: 0.9228\n",
            "Epoch 10/10\n",
            "44974/44974 [==============================] - 847s 19ms/step - loss: 0.1004 - acc: 0.9643 - val_loss: 0.2296 - val_acc: 0.9248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe2d0837320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHkEq-mtx3la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_Uni.save('LSTM+W2V.h5')\n",
        "model_Bi.save('BiLSTM+W2V.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbivvFZb6J7M",
        "colab_type": "text"
      },
      "source": [
        "**PREDICTION ON COMPETETION DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh0BZwMN6OLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "competetion_bodies = pd.read_csv(DATA_DIR+'competition_test_bodies.csv')\n",
        "competetion_stances = pd.read_csv(DATA_DIR+'competition_test_stances.csv')\n",
        "\n",
        "competetion_unlabeled = pd.read_csv(DATA_DIR+'competition_test_stances_unlabeled.csv')\n",
        "\n",
        "comp = competetion_stances.join(competetion_bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aycs347ZTPSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp.replace('unrelated',1,True)\n",
        "comp.replace('agree',2,True)\n",
        "comp.replace('disagree',3,True)\n",
        "comp.replace('discuss',4,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jy12sxhTTm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq_headline_comp = [text_to_word_sequence(sent) for sent in comp['Headline']]\n",
        "word_seq_bodies_comp = [text_to_word_sequence(sent) for sent in comp['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tmYT6-2Ti1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(word_seq_headline_comp)):\n",
        "  word_seq_headline_comp[i].extend(word_seq_bodies_comp[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wRssD3eTm-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XfIyaGTp4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_comp = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_headline_comp])\n",
        "X_comp = pad_sequences(X_comp, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_comp = comp['Stance']\n",
        "y_comp = y_comp.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjK09RxfTvT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_comp = LabelEncoder()\n",
        "encoder_comp.fit(y_comp)\n",
        "encoded_comp = encoder_comp.transform(y_comp)\n",
        "dummy_y_comp = np_utils.to_categorical(encoded_comp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCzekJLFT0zE",
        "colab_type": "code",
        "outputId": "e07b9890-3400-471d-8add-8584cb6adaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_Uni = model_Uni.predict(X_comp)\n",
        "score,acc = model_Uni.evaluate(X_comp, dummy_y_comp)\n",
        "print (\"LSTM with W2V \",score)\n",
        "\n",
        "y_Bi = model_Bi.predict(X_comp)\n",
        "score,acc = model_Bi.evaluate(X_comp, dummy_y_comp)\n",
        "print (\"BiLSTM with W2V \",score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25413/25413 [==============================] - 48s 2ms/step\n",
            "LSTM with W2V  1.3516194208807344\n",
            "25413/25413 [==============================] - 106s 4ms/step\n",
            "BiLSTM with W2V  1.519696736023342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smfUiNoRDuXI",
        "colab_type": "code",
        "outputId": "a77c917e-bc78-4c2f-ad09-5a98b4858790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#submission.csv using BiLSTM W2V\n",
        "from score import report_score\n",
        "outputs = [np.argmax(p) for p in y_Bi]\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    if outputs[i] == 0: outputs[i] = \"unrelated\"\n",
        "    if outputs[i] == 1: outputs[i] = \"disagree\"\n",
        "    if outputs[i] == 2: outputs[i] = \"agree\"\n",
        "    if outputs[i] == 3: outputs[i] = \"discuss\"\n",
        "#print (np.unique(outputs))\n",
        "\n",
        "cs = pd.read_csv(DATA_DIR+'competition_test_stances.csv')\n",
        "stance_true = cs['Stance'].values\n",
        "from score import report_score\n",
        "print (\"Weighted Score\")\n",
        "report_score(stance_true, outputs)\n",
        "\n",
        "Predicted = {}\n",
        "Predicted = pd.DataFrame({'Stance': outputs})\n",
        "result = pd.concat([competetion_unlabeled, Predicted], axis=1, sort=False)\n",
        "result.to_csv('submission_BiLSTM_W2V.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weighted Score\n",
            "41.07499195365304\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}